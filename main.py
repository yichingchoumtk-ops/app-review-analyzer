import os
import json
import requests
import pandas as pd
import gspread
from datetime import datetime
import time

# ===================================================================
# V5.1 åµéŒ¯ç‰ˆï¼šåœ¨æ¯å€‹é—œéµæ­¥é©Ÿéƒ½å¢åŠ è©³ç´°çš„æ—¥èªŒè¼¸å‡º
# ===================================================================

print("--- main.py è…³æœ¬é–‹å§‹åŸ·è¡Œ ---")

# ===================================================================
# 1. å¾ GitHub Secrets è®€å–å®‰å…¨æ†‘è­‰
# ===================================================================
print("\nSTEP 1: æ­£åœ¨å¾ç’°å¢ƒè®Šæ•¸è®€å–æ†‘è­‰...")
try:
    dify_api_key = os.environ['DIFY_API_KEY']
    dify_api_url = os.environ['DIFY_API_URL']
    google_creds_json = os.environ['GOOGLE_SHEETS_CREDENTIALS']
    print("âœ… æˆåŠŸè®€å–ç’°å¢ƒè®Šæ•¸ã€‚")

    print("  - æ­£åœ¨è§£æ Google Sheets JSON æ†‘è­‰...")
    google_creds_dict = json.loads(google_creds_json)
    print("  - âœ… Google Sheets JSON æ†‘è­‰è§£ææˆåŠŸã€‚")

except KeyError as e:
    print(f"âŒ è‡´å‘½éŒ¯èª¤ï¼šåœ¨ GitHub Secrets ä¸­æ‰¾ä¸åˆ°å¿…è¦çš„æ†‘è­‰ï¼š{e}")
    exit(1)
except json.JSONDecodeError as e:
    print(f"âŒ è‡´å‘½éŒ¯èª¤ï¼šGOOGLE_SHEETS_CREDENTIALS çš„å…§å®¹ä¸æ˜¯ä¸€å€‹æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚è«‹æª¢æŸ¥è²¼ä¸Šçš„å…§å®¹æ˜¯å¦å®Œæ•´ã€‚éŒ¯èª¤ï¼š{e}")
    exit(1)

# ===================================================================
# 2. è®¾å®š Google Sheets è¿æ¥
# ===================================================================
print("\nSTEP 2: æ­£åœ¨é€£æ¥åˆ° Google Sheets...")
try:
    gc = gspread.service_account_from_dict(google_creds_dict)
    print("  - âœ… gspread æœå‹™å¸³è™Ÿåˆå§‹åŒ–æˆåŠŸã€‚")

    spreadsheet_name = "App è©•è«–è‡ªå‹•åŒ–æ´å¯Ÿç³»çµ±"
    print(f"  - æ­£åœ¨é–‹å•Ÿè©¦ç®—è¡¨æª”æ¡ˆ: '{spreadsheet_name}'...")
    spreadsheet = gc.open(spreadsheet_name) 
    print("  - âœ… è©¦ç®—è¡¨æª”æ¡ˆé–‹å•ŸæˆåŠŸã€‚")

    worksheet_name = "è©•è«–è³‡æ–™åº« (Reviews_DB)"
    print(f"  - æ­£åœ¨é–‹å•Ÿå·¥ä½œè¡¨åˆ†é : '{worksheet_name}'...")
    worksheet = spreadsheet.worksheet(worksheet_name)
    print("  - âœ… å·¥ä½œè¡¨åˆ†é é–‹å•ŸæˆåŠŸã€‚")
    
    print(f"âœ… æˆåŠŸé€£æ¥åˆ° Google Sheet: '{spreadsheet_name}' -> Worksheet: '{worksheet_name}'")
except gspread.exceptions.SpreadsheetNotFound:
    print(f"âŒ è‡´å‘½éŒ¯èª¤: æ‰¾ä¸åˆ°åç‚º '{spreadsheet_name}' çš„ Google Sheet æª”æ¡ˆã€‚è«‹ç¢ºèªåç¨±å®Œå…¨æ­£ç¢ºï¼Œä¸”æœå‹™å¸³è™Ÿå·²è¢«æˆäºˆè©²æª”æ¡ˆçš„ç·¨è¼¯æ¬Šé™ã€‚")
    exit(1)
except gspread.exceptions.WorksheetNotFound:
    print(f"âŒ è‡´å‘½éŒ¯èª¤: åœ¨è©¦ç®—è¡¨ä¸­æ‰¾ä¸åˆ°åç‚º '{worksheet_name}' çš„åˆ†é ã€‚")
    exit(1)
except Exception as e:
    print(f"âŒ é€£æ¥ Google Sheets æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
    exit(1)

# ===================================================================
# 3. å®šä¹‰ Dify AI åˆ†æåŠŸèƒ½ (è¿™éƒ¨åˆ†ä»£ç ä¸å˜ï¼Œå…ˆçœç•¥)
# ... å®Œæ•´çš„ Dify, çˆ¬èŸ², å’Œä¸»æµç¨‹ä»£ç  ...
# ä¸ºäº†é¿å…æ··æ·†ï¼Œè¿™é‡Œè´´ä¸Šå®Œæ•´çš„ä»£ç 
# ===================================================================

from app_store_scraper import AppStore
from google_play_scraper import Sort, reviews

def analyze_with_dify(comment):
    headers = {"Authorization": f"Bearer {dify_api_key}", "Content-Type": "application/json"}
    payload = {"inputs": {"review_text": comment}, "response_mode": "blocking", "user": "github-actions-scraper"}
    try:
        response = requests.post(dify_api_url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        result_text = response.json().get('outputs', {}).get('analysis_result')
        if not result_text: raise KeyError("'analysis_result' not found in Dify response.")
        return json.loads(result_text)
    except Exception as e:
        print(f"  â””â”€ âŒ Dify åˆ†æå¤±æ•—: {e}")
        return None

def get_reviews_and_filter():
    print("\nSTEP 3: é–‹å§‹æŠ“å–èˆ‡ç¯©é¸è©•è«–...")
    apps_to_scrape = [
        {'name': 'ä¸‰ç«¹è‚¡å¸‚', 'platform': 'iOS', 'id': '352743563'},
        {'name': 'ä¸‰ç«¹è‚¡å¸‚', 'platform': 'Android', 'id': 'com.mtk'},
        {'name': 'å¯Œæœ Fugle', 'platform': 'iOS', 'id': '1542310263'},
        {'name': 'å¯Œæœ Fugle', 'platform': 'Android', 'id': 'tw.fugle.flutter.app'},
    ]
    all_new_reviews = []
    for app in apps_to_scrape:
        print(f"  â–¶ï¸  æ­£åœ¨è™•ç†: {app['name']} ({app['platform']})")
        try:
            if app['platform'] == 'iOS':
                scraper = AppStore(country='tw', app_id=app['id']); scraper.review(how_many=100)
                reviews_list = scraper.reviews
            else:
                reviews_list, _ = reviews(app['id'], lang='zh-TW', country='tw', sort=Sort.NEWEST, count=100)
            for review in reviews_list:
                all_new_reviews.append({
                    'app_name': app['name'], 'platform': app['platform'],
                    'comment': str(review.get('review') or review.get('content', '')),
                    'rating': int(review.get('rating') or review.get('score', 0)),
                    'date': (review.get('date') or review.get('at')).strftime('%Y-%m-%d %H:%M:%S')
                })
        except Exception as e: print(f"    â””â”€ âš ï¸ æŠ“å–å¤±æ•—: {e}")
    if not all_new_reviews: return []
    df = pd.DataFrame(all_new_reviews); df.drop_duplicates(subset=['comment'], inplace=True, keep='first')
    DIFY_WEEKLY_LIMIT = 40
    low_rating_reviews = df[df['rating'] <= 3].sort_values(by='date', ascending=False)
    high_rating_reviews = df[df['rating'] > 3].sort_values(by='date', ascending=False)
    if len(low_rating_reviews) >= DIFY_WEEKLY_LIMIT: reviews_to_analyze = low_rating_reviews.head(DIFY_WEEKLY_LIMIT)
    else:
        needed = DIFY_WEEKLY_LIMIT - len(low_rating_reviews)
        reviews_to_analyze = pd.concat([low_rating_reviews, high_rating_reviews.head(needed)])
    print(f"âœ… æ‰¾åˆ° {len(df)} ç­†ä¸é‡è¤‡è©•è«–ï¼Œç¯©é¸å¾Œå°‡åˆ†æ {len(reviews_to_analyze)} ç­†ã€‚")
    return reviews_to_analyze.to_dict('records')

if __name__ == "__main__":
    reviews_to_process = get_reviews_and_filter()
    final_results_to_sheet = []
    if reviews_to_process:
        print("\nSTEP 4: æ­£åœ¨ç™¼é€è©•è«–çµ¦ Dify é€²è¡Œåˆ†æ...")
        for i, review in enumerate(reviews_to_process):
            print(f"  - åˆ†æä¸­ {i+1}/{len(reviews_to_process)} ({review['app_name']}): \"{review['comment'][:40].replace('\n', ' ')}...\"")
            ai_result = analyze_with_dify(review['comment'])
            if ai_result:
                print(f"    â””â”€ ğŸ¤– AI çµæœ: {ai_result}")
                final_results_to_sheet.append({
                    'App_åç¨±': review['app_name'], 'å¹³å°': review['platform'], 'è©•è«–æ—¥æœŸ': review['date'],
                    'åŸå§‹æ˜Ÿç­‰': review['rating'], 'è©•è«–å…§å®¹': review['comment'],
                    'AIæƒ…ç·’åˆ†æ•¸': ai_result.get('emotion_score'), 'AIåˆ†é¡': ai_result.get('category'),
                    'AIç¸½çµ': ai_result.get('summary'), 'è™•ç†æ™‚é–“': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
            else: print("    â””â”€ âš ï¸ åˆ†æå¤±æ•—ï¼Œè·³éã€‚")
            time.sleep(1)
    if final_results_to_sheet:
        print(f"\nSTEP 5: æ­£åœ¨å°‡ {len(final_results_to_sheet)} ç­†çµæœå¯«å…¥ Google Sheets...")
        try:
            headers = list(final_results_to_sheet[0].keys())
            worksheet.update('A1', [headers]) # ç®€åŒ–ï¼šæ¯æ¬¡éƒ½è¦†ç›–è¡¨å¤´
            values_to_append = [list(row.values()) for row in final_results_to_sheet]
            worksheet.append_rows(values_to_append, value_input_option='USER_ENTERED')
            print("âœ… æˆåŠŸå¯«å…¥ Google Sheetsï¼")
        except Exception as e: print(f"âŒ å¯«å…¥ Google Sheets æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    print("\nğŸ‰ å·¥ä½œæµç¨‹åŸ·è¡Œå®Œç•¢ï¼")
